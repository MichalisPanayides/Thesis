\section{Queueing theoretic model}

One of the main outcomes of this research is the creation of a queueing network
model that consists of two waiting zones and accepts two types of individuals.

\input{chapters/03_queueing_model/img/queueing_model_diagram.tex}

The model consists of two types of individuals; type 1 and type 2.
Type 1 individuals arrive instantly at waiting zone 1 and wait to receive their
service.
Type 2 individuals arrive at waiting zone 2 and wait there until they are
allowed to move to waiting zone 1.
They are allowed to proceed only when the number of
individuals in waiting zone 1 \textbf{and} in service is less than a
pre-determined threshold \(T\).
When the number of individuals is equal to or exceeds this threshold, all
type 2 individuals that arrive will stay \textit{blocked} in waiting zone 2
until the number of people in waiting zone 1 falls below \(T\).
This is shown diagrammatically in Figure \ref{fig:diagram_of_queueing_system}.
The parameters of the described queueing model are:

\begin{itemize}
    \item \(\lambda_i\): The arrival rate of type \(i\) individuals where
    \(i\in\{1, 2\}\)
    \item \(\mu\): The service rate for individuals receiving service at
    waiting zone 1
    \item \(C\): The number of servers
    \item \(T\): The threshold at which individuals of the second type are
    blocked
\end{itemize}

In chapter ?
% TODO: reference chapter \ref{ch:ed-ems-application}
this queueing network will be used to model the emergent behaviour between
Emergency Departments (EDs) and the Emergency Medical Systems (EMS).

\subsection{Discrete Event Simulation}
% TODO: Write DES subsection - emphasise on custom Node + include some code for
% node class

\subsection{Markov chain model}

A Markov chain is a stochastic model that is the primary analytical tool to 
study queues.
Under the assumption that all rates (arrival and service) are Markovian the
queueing system can be represented by a Markov chain
model~\cite{kemeny1976markov}.
The states of the Markov chain are denoted by \((u,v)\) where:

\begin{itemize}
    \item \(u\) is the number of individuals blocked in waiting zone 2
    \item \(v\) is the number of individuals either in waiting zone 1 or in the
    service centre
\end{itemize}

The set of all possible combination of pairs \((u, v)\) form all the possible 
states that the system can visit.
The state space of the Markov chain is denoted as the set \(S=S(T)\) which can
be written as the disjoint union:

\begin{align}
    S(T) =& S_1(T) \cup S_2(T) \text{ where:} \nonumber \\
    S_1(T) =& \left\{(0, v)\in\mathbb{N}_0^2 \; | \; v < T \right\}
    \label{eq:definition_of_S_as_disjoint_union} \\
    S_2(T) =& \{(u, v)\in\mathbb{N}_0^2 \; | \; v \geq T \} \nonumber
\end{align}

\(S_1\) consists of the set of states where the number of individuals in waiting
zone 1 is less than \(T\) (i.e. \(v < 0\)) and subsequently the number of
individuals in waiting zone 2 is zero (i.e. \(u = 0\)).
Similarly, \(S_2\) consists of the set of states where the number of individuals
in waiting zone 1 is greater than or equal to \(T\) (i.e. \(v \geq T\)) and 
hence it is possible for individuals to be at waiting zone 2 (i.e. 
\(u \geq 0\)).
This is illustrated diagrammatically in figure \ref{fig:general_markov_model}.

Having defined the set of states of the Markov chain model, the generator
matrix can also be obtained.
The generator matrix \(Q\) of the Markov chain consists of the
rates between the numerous states of the model.
Every entry \( Q_{ij} = Q_{(u_i, v_i),(u_j, v_j)} \) represents the rate from
state \( i = (u_i, v_i) \) to state \( j = (u_j , v_j) \) for all
\( (u_i, v_i), (u_j, v_j) \in S \).
The entries of \(Q\) can be calculated using the state-mapping function
described in equation (\ref{eq:markov_transition_rate}).
Here \(\Lambda\) denotes the overall arrival rate in the model for
both types of individuals (i.e. \(\Lambda = \lambda_1 + \lambda_2\)).

\begin{equation} \label{eq:markov_transition_rate}
    Q_{ij} =
    \begin{cases}
        \Lambda, & \textbf{if } (u_i, v_i) - (u_j, v_j) = (0,-1) \textbf{ and }
        v_i < \text{t} \\
        \lambda_1, & \textbf{if } (u_i, v_i) - (u_j, v_j) = (0,-1)
        \textbf{ and } v_i \geq \text{t} \\
        \lambda_2, & \textbf{if } (u_i, v_i) - (u_j, v_j) = (-1,0) \\
        v_i \mu, & \textbf{if } (u_i, v_i) - (u_j, v_j) = (0,1) \textbf{ and }
        v_i \leq C \textbf{ or} \\ & \hspace{0.37cm}(u_i, v_i) - (u_j, v_j) =
        (1,0) \textbf{ and } v_i = T \leq C \\
        C \mu, & \textbf{if } (u_i, v_i) - (u_j, v_j) = (0,1) \textbf{ and }
        v_i > C
        \textbf{ or} \\ & \hspace{0.37cm}(u_i, v_i) - (u_j, v_j) = (1,0)
        \textbf{ and } v_i = T > C\\
        -\sum_{j=1}^{|Q|}{Q_{ij}} & \textbf{if } i = j \\
        0, & \textbf{otherwise}
    \end{cases}
\end{equation}

Note that for large values of \(N\) and \(M\) most of the entries of the
transition matrix will be zero.
In order to speed up the computation of the transition matrix, instead of
considering every possible pair of states in the state space a new function
that maps a state to every possible destination state can be used.
Equation (\ref{eq:state_map_to_destination_states}) maps a state \((u, v)\)
to all possible destination states that the system can go to when on that state.

\begin{equation}\label{eq:state_map_to_destination_states}
    \mathcal{M}(u, v) = 
    \begin{cases}
        \{(u, v + 1), (u, v - 1)\} & \textbf{if } v < T \\
        \{(u + 1, v), (u, v + 1), (u, v - 1)\} & \textbf{if } v = T 
        \textbf{ and } u = 0 \\
        \{(u + 1, v), (u, v + 1), (u - 1, v)\} & \textbf{if } v = T
        \textbf{ and } u > 0 \\
        \{(u, v + 1), (u + 1, v), (u, v - 1)\} & \textbf{if } v > T \\
    \end{cases}
\end{equation}


A visualisation of how the transition rates relate to the states of the model
can be seen in the general Markov chain model shown in Figure
\ref{fig:general_markov_model}.

\input{chapters/03_queueing_model/img/general_markov_model.tex}


In order to consider this model numerically an adjustment needs to be made.
The problem defined above assumes no upper boundary to the number of individuals
that can wait for service or for the ones that are blocked in waiting zone 2.
Therefore, a different state space \( \tilde S \) is constructed where
\( \tilde S \subseteq S \) and there is a maximum allowed number of individuals
\(N\) that can be in waiting zone 1 and a maximum allowed number of individuals
\(M\) that can be blocked in waiting zone 2:

\begin{equation}\label{eq:truncated_state_space}
    \tilde S = \left\{ (u, v) \in S\;| u \leq M, v\leq N \right\}
\end{equation}

The adjusted Markov chain model with states \(\tilde S\) can be seen in Figure
\ref{fig:adjusted_markov_model}.

\input{chapters/03_queueing_model/img/general_adjusted_markov_model.tex}



\subsubsection{Steady state probability vector \(\pi\)}

The generator matrix \( Q \) defined in (\ref{eq:markov_transition_rate}) can
be used to get the probability vector \( \pi \) that contains the steady state
probabilities of the Markov chain model.
The vector \( \pi \) is commonly used to study stochastic systems and it's main
purpose is to keep track of the probability of being at any given state of
the Markov chain model.
\(\pi_i\) is the steady state probability of being in state \((u_i, v_i) \in
\tilde S\) which is the \(i^{\text{th}}\) state of \(\tilde S\) for some
ordering of \(\tilde S\).
The term \textbf{steady state} refers to the instance of the vector \( \pi \)
where the probabilities of being at any state becomes stable over time.
Thus, by considering the steady state vector \( \pi \) the relationship between
it and \( Q \) is given by:

\begin{equation}\label{eq:steady_state_from_generator_matrix}
    \frac{d\pi}{dt} = \pi Q = \vec{0}
\end{equation}


\subsubsection{Numerical integration approach}

Another method that can be used to get the steady state probability vector is
to solve the differential equation from equation
\ref{eq:steady_state_from_generator_matrix} numerically.
Two methods of solving the differential equation were considered.
Both methods observe the value of \(\pi\) over time until it
reaches the steady state based on some initial starting value \(\pi_0\):

\begin{gather}
    \frac{d\pi}{dt} = \pi Q \\
    \pi(t_0) = \pi_0 \nonumber \\
    \text{where } \pi_0 = 
    [\frac{1}{|\pi|}, \frac{1}{|\pi|}, \dots, \frac{1}{|\pi|}] \nonumber
\end{gather}

Two types of methods were considered to solve the differential equation
numerically.
The first method uses a combination of Adams' method~\cite{adams_method} and the
backward differentiation formula (BDF)~\cite{backward_differentiation_formula}.
This method is generally used to solve systems of the form
\(\frac{dy}{dt} = f\) with a dense or banded Jacobian when the problem is stiff,
which then uses the BDF algorithm, while when the problem is non-stiff it uses
Adams' method.
This was implemented using \textit{scipy.integrate. odeint} from the python
library \textit{SciPy}~\cite{2020SciPy-NMeth} that uses the
\textit{lsoda}~\cite{lsoda_algorithm} integration method.

The second approach uses the explicit Runge-Kutta integration method of order 5
by controlling the error assuming accuracy of order 4
\cite{solve_ivp_rk45_method, runge_kutta_formulas}.
The general recursive formula for the explicit family of Runge-Kutta methods is
given by:

\begin{equation}
    y_{n+1} = y_n + h \sum_{i=1}^s b_i k_i
\end{equation}
\begin{align}
    k_1 & = f(t_n, y_n), \nonumber \\
    k_2 & = f(t_n+c_2h, y_n+h(a_{21}k_1)), \nonumber \\
    k_3 & = f(t_n+c_3h, y_n+h(a_{31}k_1+a_{32}k_2)), \nonumber \\
        & \ \ \vdots \nonumber \\
    k_s & = f(t_n+c_s h, y_n+h(a_{s1}k_1+a_{s2}k_2+\cdots+a_{s,s-1}k_{s-1})) 
    \nonumber
\end{align}

where \(y_0\) is the given initial value, \(s\) is the number of stages and
\(h\) is the step size.
The coefficients \(b_i\), \(c_i\), and \(a_{ij}\) are usually arranged in a
mnemonic device known as the Butcher's tableau.
This was implemented using \textit{scipy.integrate. solve\_ivp} from the python
library \textit{SciPy}~\cite{2020SciPy-NMeth}.


\subsubsection{Linear algebraic approach}

The steady state probability vector \( \pi \) can be obtained by solving the
linear equation:

\begin{equation}\label{eq:numpy_linalg_solve_1}
    Q^T \pi = \vec{0} \hspace{0.5cm} \text{such that} \hspace{0.5cm} 
    \sum_{i} \pi_i = 1
\end{equation}

The two equations can be combined into one by augmenting the matrix \( Q^T \)
in such a way that it includes the extra constraint \( \sum_i \pi_i = 1 \).
The new augmented matrix \(\tilde Q\) is defined as \(Q\) with the final
column replaced with a vector of ones and vector \(\vec{b}\) is defined
as a column vector of \(0\)s apart from the final element which is \(1\).
Note that, \(\tilde Q\) needs to be a square matrix in order to solve the
equation using linear algebra (i.e. the matrix needs to be invertible).
Thus, the steady state probability vector can be calculated by solving the
linear equation:

\begin{equation}
    \tilde Q^T \pi = \vec{b}
\end{equation}

Using LU decomposition with partial pivoting and row interchanges, matrix
\(Q^T\) can be expressed of the form \(P \times L \times U\), where \(P\) is
a permutation matrix, \(L\) is a unit lower triangular matrix, and \(U\) is
an upper triangular matrix~\cite{strang2006linear}.
The factored form of \(Q^T\) can then be used to solve the system.
This was implemented using \textit{numpy.linalg.solve} from the
python library \textit{numpy} \cite{2020NumPy-Array} \cite{lapack99}.


\subsubsection{Least squares approach}

Another approach that is considered is the least squares method. 
As the problem becomes more complex (i.e. as the artificial parameters \(N\)
and \(M\) defined in equation \ref{eq:truncated_state_space} increase)
the computational time required to solve it increases by a lot.
Thus, one may obtain a good approximation of the steady state vector \( \pi \)
by solving the following equation:

\begin{equation}
    \pi = \text{argmin}_{\pi \in \mathbb{R}^{|\pi|}}\|\tilde Q^T \pi - b\|_2^2
\end{equation}

The above expression gets the vector \( \pi \) that approximately solves 
equation \(\tilde Q^T \pi = b\).
This was implemented using \textit{numpy.linalg.lstsq} from the python 
library \textit{numpy}~\cite{2020NumPy-Array}.

\subsubsection{Closed-form approach}
% TODO: Write closed form section to get steady state

\subsection{Performance measures}
Using vector \(\pi\) there are numerous performance measures of the model that
can be calculated.
The following equations utilise \(\pi\) to get performance measures on the
average number of individuals in waiting zone 1 and in waiting zone 2:

\begin{itemize}
    \item Mean number of individuals in the entire system:
        \begin{equation}
            L_S = \sum_{i=1}^{|\pi|} \pi_i (u_i + v_i)
        \end{equation}
    \item Mean number of individuals in waiting zone 1:
        \begin{equation}
            L_1 = \sum_{i=1}^{|\pi|} \pi_i v_i
        \end{equation}
    \item Mean number of individuals in waiting zone 2:
        \begin{equation}
            L_2 = \sum_{i=1}^{|\pi|} \pi_i u_i
        \end{equation}
\end{itemize}

Consequently, there are some additional performance measures of interest that
are not as straightforward to calculate.
Such performance measures are the mean waiting time in the system (for both
type 1 and type 2 individuals), the mean time blocked in waiting zone 2 (only
valid for type 2 individuals) and the proportion of individuals that wait in
waiting zone 1 within a predefined time target (for both types).

\subsubsection{Waiting time}
% TODO: Write waiting time subsection

\subsubsection{Blocking time}
% TODO: Write blocking time subsection

\subsubsection{Proportion of individuals within target}
% TODO: Write proportion of individuals within target subsection


\subsection{Numeric results and timings}
% TODO: Write numeric results and timings section (compare DES with Markov)


\subsection{ED-EMS application}
% TODO: Write ED-EMS application subsection